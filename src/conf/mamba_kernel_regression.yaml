# Example configuration for training Mamba on a toy task

inherit:
    - wandb.yaml # Inherit wandb settings if needed

model:
  family: "mamba"
  n_dims: 20
  n_positions: 101
  n_embd: 128
  n_layer: 4
  # Mamba specific params (using defaults from mamba_model.py)
  d_state: 16
  expand: 2
  dt_rank: "auto"
  d_conv: 4
  conv_bias: True
  bias: False # Mamba default

training:
    task: kernel_regression # Example task
    data: gaussian          # Example data distribution
    task_kwargs: {}         # Task-specific arguments
    batch_size: 64
    learning_rate: 0.0001
    save_every_steps: 1000
    keep_every_steps: 100000
    train_steps: 500001       # Match toy.yaml for comparison
    curriculum:             # Keep curriculum same as toy.yaml for comparison
        dims:
            start: 5
            end: 5
            inc: 1
            interval: 2000
        points:
            start: 10
            end: 40
            inc: 2
            interval: 2000

out_dir: "../models/mamba"

wandb:
  name: mamba_toy
